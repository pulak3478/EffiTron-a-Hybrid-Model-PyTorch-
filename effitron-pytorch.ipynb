{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass TransformerEncoderBlock(nn.Module):\n    def __init__(self, embed_dim=1280, num_heads=4, ff_dim=256, dropout=0.1):\n        super(TransformerEncoderBlock, self).__init__()\n        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n        self.norm1 = nn.LayerNorm(embed_dim)\n        self.norm2 = nn.LayerNorm(embed_dim)\n\n        self.ffn = nn.Sequential(\n            nn.Linear(embed_dim, ff_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(ff_dim, embed_dim)\n        )\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # Self-Attention\n        attn_output, _ = self.attn(x, x, x)\n        x = self.norm1(x + self.dropout(attn_output))\n\n        # Feedforward\n        ff_output = self.ffn(x)\n        x = self.norm2(x + self.dropout(ff_output))\n\n        return x\n\nclass EffTransNet(nn.Module):\n    def __init__(self, num_classes=5, transformer_depth=2):\n        super(EffTransNet, self).__init__()\n\n        # Load pretrained EfficientNetB0\n        backbone = models.efficientnet_b0(pretrained=True)\n        self.backbone = nn.Sequential(*list(backbone.children())[:-2])  # Exclude classifier\n\n        self.embed_dim = 1280\n        self.transformer_layers = nn.Sequential(\n            *[TransformerEncoderBlock(embed_dim=self.embed_dim) for _ in range(transformer_depth)]\n        )\n\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.classifier = nn.Linear(self.embed_dim, num_classes)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        x = self.backbone(x)              # [B, 1280, 7, 7]\n        x = x.view(batch_size, self.embed_dim, -1).permute(0, 2, 1)  # [B, 49, 1280]\n        x = self.transformer_layers(x)    # [B, 49, 1280]\n        x = self.pool(x.permute(0, 2, 1)).squeeze(-1)  # [B, 1280]\n        x = self.classifier(x)            # [B, num_classes]\n        return x\n\n# Instantiate model\nmodel = EffTransNet(num_classes=5).to(device)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# Optional: Model Summary\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:37:23.820738Z","iopub.execute_input":"2025-05-31T10:37:23.821024Z","iopub.status.idle":"2025-05-31T10:37:35.840979Z","shell.execute_reply.started":"2025-05-31T10:37:23.820993Z","shell.execute_reply":"2025-05-31T10:37:35.839834Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 145MB/s]\n","output_type":"stream"},{"name":"stdout","text":"EffTransNet(\n  (backbone): Sequential(\n    (0): Sequential(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SiLU(inplace=True)\n      )\n      (1): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (2): Conv2dNormActivation(\n              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n        )\n      )\n      (2): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n        )\n      )\n      (3): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n        )\n      )\n      (4): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n        )\n      )\n      (5): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n        )\n      )\n      (6): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n        )\n      )\n      (7): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n        )\n      )\n      (8): Conv2dNormActivation(\n        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SiLU(inplace=True)\n      )\n    )\n  )\n  (transformer_layers): Sequential(\n    (0): TransformerEncoderBlock(\n      (attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n      )\n      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=256, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.1, inplace=False)\n        (3): Linear(in_features=256, out_features=1280, bias=True)\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (1): TransformerEncoderBlock(\n      (attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n      )\n      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=256, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.1, inplace=False)\n        (3): Linear(in_features=256, out_features=1280, bias=True)\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (pool): AdaptiveAvgPool1d(output_size=1)\n  (classifier): Linear(in_features=1280, out_features=5, bias=True)\n)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Use your own dataset and train it","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = datasets.ImageFolder(\"your_dataset_path\", transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train and get your result","metadata":{}},{"cell_type":"code","source":"for epoch in range(10):\n    model.train()\n    total_loss, correct = 0, 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        correct += (outputs.argmax(1) == labels).sum().item()\n\n    acc = correct / len(train_loader.dataset)\n    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Accuracy: {acc*100:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}